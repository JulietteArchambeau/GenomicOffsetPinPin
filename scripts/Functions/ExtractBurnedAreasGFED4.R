# This function is based on the function `get_gfed4` from the `caliver` package
# https://github.com/ecmwf/caliver/blob/master/R/get_gfed4.R

# The function `get_gfed4` didn't work for me when I tried to run it several times, I had the following warning:
# "Server currently unavailable, please try again later
# which was likely to be related to the too high number of connections to the domain in a small amount of time.

# With the help of Charlie Pauvert, we modified the function mainly by adding `Sys.sleep(x)`
# But this was not perfect as it worked only one time, after I had to increase the `Sys.sleep`...


get_gfed4 <- function(start_date = NULL,
                      end_date = NULL,
                      temporal_resolution = "daily",
                      varname = NULL,
                      region = "GLOB"){
  
  if (is.null(varname)) stop("Please enter valid varname")
  if (is.null(region)) stop("Please enter valid region")
  if (varname == "BasisRegions") {
    
    if (is.null(region)) stop("Please enter valid region")
    
    base_url <- "http://www.geo.vu.nl/~gwerf/GFED/GFED4/"
    fname <- "GFED4.1s_2015.hdf5"
    the_url <- paste0(base_url, fname)
    x <- try(RCurl::getURL(the_url), silent = TRUE)
    
    if (class(x) == "try-error") {
      
      stop("Server currently unavailable, please try again later.")
      
    } else {
      
      # Download the file
      out_filename <- tempfile()
      download.file(url = the_url, destfile = out_filename,
                    quiet = TRUE, cacheOK = TRUE, mode = "wb")
      
      # Extract dataset with basis regions
      file_h5 <- hdf5r::h5file(out_filename)
      # lets look at the content: file.h5$ls(recursive=TRUE)
      # Extract dataset
      br <- file_h5[["ancill/basis_regions"]]
      
      # Convert hdf5 to raster
      regions_raster <- raster::raster(br[, ])
      
      # Transform the raster
      regions_raster_t <- .transform_raster(regions_raster, varname)
      
      # Define zeros as NAs
      regions_raster_t[regions_raster_t == 0] <- NA
      
      if (!is.null(region)) {
        if (region == "BONA") regions_raster_t[regions_raster_t != 1] <- NA
        if (region == "TENA") regions_raster_t[regions_raster_t != 2] <- NA
        if (region == "CEAM") regions_raster_t[regions_raster_t != 3] <- NA
        if (region == "NHSA") regions_raster_t[regions_raster_t != 4] <- NA
        if (region == "SHSA") regions_raster_t[regions_raster_t != 5] <- NA
        if (region == "EURO") regions_raster_t[regions_raster_t != 6] <- NA
        if (region == "MIDE") regions_raster_t[regions_raster_t != 7] <- NA
        if (region == "NHAF") regions_raster_t[regions_raster_t != 8] <- NA
        if (region == "SHAF") regions_raster_t[regions_raster_t != 9] <- NA
        if (region == "BOAS") regions_raster_t[regions_raster_t != 10] <- NA
        if (region == "CEAS") regions_raster_t[regions_raster_t != 11] <- NA
        if (region == "SEAS") regions_raster_t[regions_raster_t != 12] <- NA
        if (region == "EQAS") regions_raster_t[regions_raster_t != 13] <- NA
        if (region == "AUST") regions_raster_t[regions_raster_t != 14] <- NA
      }
      
      # Trim outer NAs
      regions_raster_t_no_na <- raster::trim(regions_raster_t)
      
      # Convert to polygons
      regions_polygons <- raster::rasterToPolygons(x = regions_raster_t_no_na)
      
      return(regions_polygons)
      
    }
    
  } else {
    
    if (is.null(start_date)) stop("Invalid start_date")
    if (is.null(end_date)) stop("Invalid valid end_date")
    if (is.null(temporal_resolution)) stop("Invalid temporal_resolution")
    
    base_url <- "ftp://fuoco.geog.umd.edu/gfed4"
    
    if (temporal_resolution == "monthly"){
      
      lookuptable <- data.frame(id = 1:7,
                                varnames = c("BurnedArea",
                                             "BurnedAreaUncertainty",
                                             "source",
                                             "TreeCoverDist",
                                             "LandCoverDist",
                                             "FirePersistence",
                                             "PeatFraction"),
                                factor = c(0.01, 0.01, 1, 1, 1, 0.01, 1),
                                stringsAsFactors = FALSE)
      
      seq_of_dates <- seq.Date(from = as.Date(start_date),
                               to = as.Date(end_date),
                               by = "month")
      my_dates <- substr(x = gsub("-", "", as.character(seq_of_dates)),
                         start = 1, stop = 6)
      # Assemble file names
      fnms <- paste0(base_url, "/", temporal_resolution, "/",
                     "GFED4.0_MQ_", my_dates, "_BA.hdf")
      
    }
    
    if (temporal_resolution == "daily") {
      
      lookuptable <- data.frame(id = 1:7,
                                varnames = c("BurnedArea",
                                             "BurnedAreaUncertainty",
                                             "MeanBurnDateUncertainty",
                                             "source",
                                             "TreeCoverDist",
                                             "LandCoverDist",
                                             "PeatFraction"),
                                factor = c(0.01, 0.01, 1, 1, 1, 1, 1),
                                stringsAsFactors = FALSE)
      
      seq_of_dates <- seq.Date(from = as.Date(start_date),
                               to = as.Date(end_date),
                               by = "day")
      day_of_year <- lubridate::yday(seq_of_dates)
      day_of_year_3_chr <- stringr::str_pad(day_of_year, 3, pad = "0")
      just_year <- substr(x = gsub("-", "", as.character(seq_of_dates)),
                          start = 1, stop = 4)
      # Assemble file names
      fnms <- paste0(base_url, "/", temporal_resolution, "/", just_year, "/",
                     "GFED4.0_DQ_", just_year, day_of_year_3_chr, "_BA.hdf")
      
    }
    
    # Loop through dates to populate the stack
    for (i in seq_along(fnms)) {
      
      message(paste("Downloading", fnms[i]))
      # Download the file
      x <- try(RCurl::getBinaryURL(fnms[i],
                                   userpwd = "fire:burnt",
                                   ftp.use.epsv = FALSE,
                                   .opts = list(timeout = 1000,
                                                connecttimeout = 1000,
                                                maxredirs = 20)),
               silent = FALSE)
      
      Sys.sleep(1)
      
      if (class(x) == "try-error") {
        
        stop("Server currently unavailable, please try again later.")
        
      } else {
        
        # Get subdataset index corresponding to my variable
        idx <- lookuptable$id[lookuptable$varname == varname]
        factorx <- lookuptable$factor[lookuptable$varname == varname]
        
        # Download the file
        hdf_file_path <- tempfile(fileext = ".hdf")
        writeBin(x, con = hdf_file_path)
        
        # Get subdataset names
        sds <- gdalUtils::get_subdatasets(hdf_file_path)[idx]
        message(paste("Importing subdataset:", sds, collapse = "\n"))
        
        # Translate subdataset from hdf file to tiff, this is needed because no
        # cross-platform direct translation to nc is available
        temp_tif_file <- tempfile(fileext = ".tif")
        gdalUtils::gdal_translate(src_dataset = sds[idx],
                                  dst_dataset = temp_tif_file)
        
        if (i == 1){
          s <- raster::raster(temp_tif_file)
        }else{
          s <- raster::stack(s, raster::raster(temp_tif_file))
        }
        
      }
      
    }
    
    return(s)
    # # Apply scaling factor
    # if (factorx != 1) s <- s * factorx
    # 
    # # Transform the raster
    # regions_raster_t <- .transform_raster(s, varname)
    # 
    # if (raster::nlayers(regions_raster_t) == 1){
    #   regions_raster_t <- regions_raster_t[[1]]
    # }
    # 
    # # Set missing crs
    # raster::crs(regions_raster_t) <- "+proj=longlat +datum=WGS84 +no_defs"
    # 
    # return(regions_raster_t)
    
  }
  
}
