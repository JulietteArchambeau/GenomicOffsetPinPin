---
title: "Creating, formatting and calculating LD for the three sets of SNPs"
author: "Juliette Archambeau"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    # code_fold: hide
    toc: true
    toc_depth: 4
    toc_float:
       collapsed: false
    number_sections: true
    highlight: textmate
editor_options: 
  chunk_output_type: console
---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

<style type="text/css">
div.main-container {
  max-width: 2000px;
  margin-left: auto;
  margin-right: auto;
}
</style>


```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 600px;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 5,fig.height = 4,cache=FALSE)
options(width = 300)
library(knitr)
library(xtable)
library(tidyverse)
library(hierfstat)
library(genetics)
library(kableExtra)
```


```{r FunctionUsed, echo=F}
# function to compute the matrix of p-value
# From http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram
corpmat <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat<- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ...)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
```


# Creating three sets of SNPs

We first create a list of three sets of SNPs that will be used to calculate the genomic offset.

  - The **reference SNPs** (analyses only shown in the Supplementary Information).

  - the **common candidates**: with *both* BF > 5dB in BayPass and SNP loadings > 3 sd cutoff in the RDA for the chosen set of covariates.

  - the **merged candidates**: with *either* BF > 5dB in BayPass or SNP loadings > 3 sd cutoff in the RDA for the chosen set of covariates.
                

## Load data

We load the genomic dataset in which there is missing data (i.e. no imputation of the missing data).

```{r LoadGenomicData}
geno <- read.csv("data_DRYAD/FormattedFilteredGenomicData_454clones_9817snps.csv",row.names = 1)
```


> Load the Baypass candidates.

```{r LoadCandBayPass}
candBaypass <- read.csv("data_DRYAD/BayPassGEAAnalysis/CandSNPsBayPassIS.csv")
candBaypass  %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

Column meaning:

  - `snp`: SNP ID used in the present study. 
  
  - `medianBF`: **median estimate of the Bayes Factor** in dB units across the five independant runs (measuring the support of the association of each SNP with each environmental covariate).
  
  - `medianBeta`: **median estimate of the regression coefficients** ($\beta_i$ in the standard covariate model) across the five independant runs (measuring the strength of the association of each SNP with each environmental covariate).
  
  - `medianEBP`: **median estimate of the empirical Bayesian P-values** in the $\log_{10}$ scale (measuring the support in favor of a non-null regression coefficient).
  
  -  `COVARIABLE`: **environmental covariate** associated with the candidate SNP.
  

> Load the RDA candidates.

```{r LoadCandRDA}
candRDA <- read.csv("data_DRYAD/RDAGEAAnalysis/CandSNPsRDA.csv")
candRDA[1:10,]  %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

Column meaning:

  - `snp`: SNP ID used in the present study. 
  
  - `bio5` ...  `BurnedArea`: correlation with each environmental covariate.
  
  - `predictor`: main predictor for each SNP.
  
  -  `correlation`: correlation with the main predictor.


## Merged candidates

```{r MergedCand}
mergedcand <- candBaypass %>% 
  filter(COVARIABLE %in% c("bio5","bio6","bio12","bio15","water_top","depth_roots","TRI","BurnedArea")) %>% 
  full_join(candRDA,by="snp")  %>% 
  dplyr::select(snp,COVARIABLE,medianBF,medianBeta,contains("bio"),water_top,depth_roots,BurnedArea,TRI) %>% 
  dplyr::rename(varBaypass=COVARIABLE,
         BF.Baypass=medianBF,
         beta.Baypass=medianBeta,
         beta.bio5.RDA=bio5,
         beta.bio6.RDA=bio6,
         beta.bio12.RDA=bio12,
         beta.bio15.RDA=bio15,
         beta.water_top.RDA=water_top,
         beta.depth_roots.RDA=depth_roots,
         beta.BurnedArea.RDA=BurnedArea,
         beta.TRI.RDA=TRI) 

mergedcand %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

There are **`r length(mergedcand$snp)` merged candidates.**


## Common candidates


```{r ComCand}
comcand <- candBaypass %>% 
  filter(COVARIABLE %in% c("bio5","bio6","bio12","bio15","water_top","depth_roots","TRI","BurnedArea")) %>% 
  inner_join(candRDA,by="snp") %>% 
  dplyr::select(snp,COVARIABLE,medianBF,medianBeta,contains("bio"),water_top,depth_roots,BurnedArea,TRI) %>% 
  dplyr::rename(varBaypass=COVARIABLE,
         BF.Baypass=medianBF,
         beta.Baypass=medianBeta,
         beta.bio5.RDA=bio5,
         beta.bio6.RDA=bio6,
         beta.bio12.RDA=bio12,
         beta.bio15.RDA=bio15,
         beta.water_top.RDA=water_top,
         beta.depth_roots.RDA=depth_roots,
         beta.BurnedArea.RDA=BurnedArea,
         beta.TRI.RDA=TRI) 

comcand %>% 
  kable() %>% 
  kable_styling(bootstrap_options = c("hover", "condensed"), full_width = F)
```

There are **`r length(comcand$snp)` candidates under expected strong selection**.

## List of SNP subsets

```{r CreatingListSnpSets}
snp.sets <- list(rownames(geno), # Reference SNPs
                 mergedcand$snp, # Merged candidates
                 comcand$snp)    # Common candidates

names(snp.sets) <- c("Ref","Mer","Com")
# saveRDS(snp.sets,file=paste0("data_DRYAD/ListNamesCandSNPs.rds")) # maybe no need to save the list in the repository
```

# Formatting genomic data for GF

In the GF analysis, we have to format the genomic data with **population allele frequencies.**

```{r CalculateAlleleFrequenciesForGF, eval=F}
list.freq <- sapply(snp.sets, function(x){ 

  geno %>% 
  filter(rownames(.) %in% x) %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column(var="prov") %>% 
  mutate(prov=str_sub(prov,1,3)) %>% 
  group_by(prov) %>% 
  summarise_all(~sum(., na.rm = TRUE)/((n()-sum(is.na(.)))*2))

  }, USE.NAMES = TRUE,simplify=FALSE)
```

For the GF analysis, we have to **remove the SNPs that are polymorphic in 5 or less than 5 populations.**

```{r RmMinorAlleleFrequencies,eval=F}
list.freq <- sapply(list.freq, function(mat){ 
  
  vec <- apply(mat[,-1],2,function(x) length(unique(x)))
  vecsup <- vec[vec>5]
  snps <- names(vecsup) # SNPs that are polymorphic in more than 5 populations
  mat <- mat %>% dplyr::select(prov,all_of(snps))
    
}, USE.NAMES = TRUE,simplify=FALSE)

saveRDS(list.freq,file="data_DRYAD/ListAlleleFrequencies.rds")
```

```{r LoadListAlleleFrequencies, echo=F}
list.freq <- readRDS(file="data_DRYAD/ListAlleleFrequencies.rds")
```


<span style="color: red;">We use **`r  sapply(list.freq, function(x) ncol(x))[[1]]` reference SNPs**, **`r  sapply(list.freq, function(x) ncol(x))[[2]]` merged SNPs** and **`r  sapply(list.freq, function(x) ncol(x))[[3]]` common SNPs** in the GF analysis.</span>

# Formatting genomic data for GDM

For the GDM analysis, we use matrices of pairwise $F_{ST}$.

```{r FormatGenomicData}
geno[geno ==1] <- 12
geno[geno ==2] <- 22
geno[geno ==0] <- 11

geno <- geno %>% 
  t() %>% 
  as.data.frame() %>% 
  dplyr::mutate(prov=substr(row.names(.), 0, 3)) %>% 
  dplyr::select(prov, everything())

geno[1:10,1:10] %>%  
  kable() %>%  
  kable_styling(font_size = 11,bootstrap_options = c("stripped","hover", "condensed"), full_width = F) %>%
  column_spec(1, bold = T)
```

To estimate the pairwise $F_{ST}$, we use the **Weir and Cockerham method**, with the function `pairwise.WCfst` of the `hierfstat` package. We could have used the function `gene.dist` (with the option `WC84`), as in [Gougherty et al. (2020)](https://www.biorxiv.org/content/10.1101/2020.02.28.961060v1.abstract). `gene.dist` keeps only the lower triangle of the $F_{ST}$ matrix, while `pairwise.WCfst` keeps the whole matrix.

```{r CalculatePairwiseFstMatrices, eval=F}
list.fst <- sapply(snp.sets[1:3], function(x){ 
  
  geno %>% 
  dplyr::select(prov,all_of(x)) %>%
  pairwise.WCfst(diploid=TRUE)
    
}, USE.NAMES = TRUE,simplify=FALSE)

# save it
saveRDS(list.fst,file="data_DRYAD/ListPairwiseFst.rds")
```

```{r LoadPairwiseFstMatrices,echo=F}
list.fst <- readRDS(file="data_DRYAD/ListPairwiseFst.rds")
```

## Negative values

```{r NegValuestoZeroFstMatrix}
NegValues <- sapply(list.fst, function(x){
  length(x[which(x <0)])
}, USE.NAMES = TRUE,simplify=FALSE)
```

There are some negative values in the pairwise $F_{ST}$ matrices:

  - `r NegValues[["Ref"]]` in the matrix of the reference SNPs.
  - `r NegValues[["Mer"]]` in the matrix of the merged candidates.
  - `r NegValues[["Com"]]` in the matrix of the common candidates.
  

It generally means there is more variation within than between provenances and is well known to result from uneven sample sizes.

## Scaling the $F_{ST}$ matrices

We have to scale the $F_{ST}$ matrices between 0 and 1 to facilitate model convergence and to enable comparisons between reference and associated SNPs that displayed different ranges of observed $F_{ST}$ values.

We standardize the $F_{ST}$ values in the following way:

$$x_{new} = \frac{x- x_{min}}{x_{max}-x_{min}} $$

This was proposed here: https://www.statisticshowto.com/probability-and-statistics/normal-distributions/normalized-data-normalization/


```{r ScalingFSTmatrixStandardization}
ScaledMatrices <- sapply(list.fst, function(x){
  
 (x-min(x,na.rm=T))/(max(x,na.rm=T)-min(x,na.rm=T))
  
}, USE.NAMES = TRUE,simplify=FALSE)


sapply(ScaledMatrices, function(x){range(x,na.rm=T)}, USE.NAMES = TRUE,simplify=FALSE)
```

## Visualization

```{r visualizeMatrixFunctions}
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

VizMatrix <- function(x) {

  p.mat <- corpmat(x)

  corrplot::corrplot(x, method="color", col=col(200),
                   type="upper", order="hclust", 
                   addCoef.col = "black", # Add coefficient of correlation
                   tl.col="black", tl.srt=23, #Text label color and rotation
                   # Combine with significance
                   p.mat = p.mat, sig.level = 0.05, insig = "blank", number.cex =0.8,tl.cex = 0.8,
                   # hide correlation coefficient on the principal diagonal
                   diag=FALSE)
}
```

### Reference SNPs

```{r VizPairwiseFstMatrixRef, fig.height=14, fig.width=14}
VizMatrix(ScaledMatrices[["Ref"]])
```

### Merged candidate SNPs

```{r VizPairwiseFstMatrixMer, fig.height=14, fig.width=14}
VizMatrix(ScaledMatrices[["Mer"]])
```


### Common candidate SNPs

```{r VizPairwiseFstMatrixCom, fig.height=14, fig.width=14}
VizMatrix(ScaledMatrices[["Com"]])
```


## Saving 

Let's format for the `gdm` package: the distance matrix must have as the first column the names of the populations.

```{r SavingForGDM}
ScaledMatrices <- sapply(ScaledMatrices, function(x){
  
  x <- x %>% 
    as.data.frame() %>% 
    tibble::rownames_to_column("prov") 
  
}, USE.NAMES = TRUE,simplify=FALSE)


saveRDS(ScaledMatrices,file="data_DRYAD/ListPairwiseFstScaled.rds")
```

# Calculating LD for each SNP set

```{r CalculatingLDForEachSNPSet, eval=F}
data <- read.csv("data_DRYAD/RawGenomicData.csv") %>% 
  dplyr::select(-clone,-assay)


# Reference SNPs
# ==============
sub.LD <- data %>% dplyr::select(all_of(snp.sets$Ref))

sub.LD <- makeGenotypes(sub.LD)
LD <- LD(sub.LD)

saveRDS(LD, file="data_DRYAD/LD/outputsLDGenetics_Ref.rds")



# Common candidates
# =================
sub.LD <- sub %>% dplyr::select(all_of(snp.sets$Com))

sub.LD <- makeGenotypes(sub.LD)
LD <- LD(sub.LD)

saveRDS(LD, file="data_DRYAD/LD/outputsLDGenetics_Com.rds")


# Merged candidates
# =================
sub.LD <- sub %>% dplyr::select(all_of(snp.sets$Mer))

sub.LD <- makeGenotypes(sub.LD)
LD <- LD(sub.LD)

saveRDS(LD, file="data_DRYAD/LD/outputsLDGenetics_Mer.rds")
```

```{r GenerateTableLD}
tab <- tibble("SNP sets"=names(snp.sets), minimum=NA, maximum=NA,mean=NA,median=NA)

# Load LD outputs
for(i in names(snp.sets)){
  LD <- readRDS(file=paste0("data_DRYAD/LD/outputsLDGenetics_",i,".rds"))
  tab[tab$`SNP sets`==i,"minimum"] <- range(LD$`R^2`,na.rm=T)[[1]]
  tab[tab$`SNP sets`==i,"maximum"] <- range(LD$`R^2`,na.rm=T)[[2]]
  tab[tab$`SNP sets`==i,"mean"] <- mean(LD$`R^2`,na.rm=T)
  tab[tab$`SNP sets`==i,"median"] <- median(LD$`R^2`,na.rm=T)
}

tab  %>% 
  kable() %>%  
  kable_styling(font_size=14,
                bootstrap_options = c("stripped","hover", "condensed"), full_width = F) %>%
  column_spec(1, bold = T)

# Generate the latex table
print(xtable(tab, type = "latex",digits=2), 
      file = "tables_paper/LDtab.tex", 
      include.rownames=FALSE)
```
